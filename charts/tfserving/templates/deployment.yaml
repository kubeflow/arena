{{- $gpuCount := .Values.gpuCount -}}
{{- $gpuMemory := .Values.gpuMemory -}}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ template "tensorflow-serving.fullname" . }}
  labels:
    heritage: {{ .Release.Service | quote }}
    release: {{ .Release.Name | quote }}
    chart: {{ template "tensorflow-serving.chart" . }}
    app: {{ template "tensorflow-serving.name" . }}
    servingName: "{{ .Values.servingName }}"
    servingType: "tf-serving"
    serviceName: "{{ .Values.servingName }}"
    servingVersion: "{{ .Values.servingVersion }}"
  annotations:
    "helm.sh/created": {{ .Release.Time.Seconds | quote }}
spec:
  replicas: {{ .Values.replicas }}
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      release: {{ .Release.Name | quote }}
      app: {{ template "tensorflow-serving.name" . }} 
  template:
    metadata:
      annotations:
        {{- if eq .Values.enableIstio true }}
          sidecar.istio.io/inject: "true"
        {{- end }}
        {{- range $key, $value := .Values.annotations }}
          {{ $key }}: {{ $value | quote }}
        {{- end }}
      labels:
        heritage: {{ .Release.Service | quote }}
        release: {{ .Release.Name | quote }}
        chart: {{ template "tensorflow-serving.chart" . }}
        app: {{ template "tensorflow-serving.name" . }}
        serviceName: "{{ .Values.servingName }}"
        servingName: "{{ .Values.servingName }}"
        servingType: "tf-serving"
        servingVersion: "{{ .Values.servingVersion }}"
    spec:
      {{- if ne (len .Values.nodeSelectors) 0 }}
      nodeSelector:
      {{- range $nodeKey,$nodeVal := .Values.nodeSelectors }}
        {{ $nodeKey }}: "{{ $nodeVal }}"
      {{- end }}
      {{- end }}
      {{- if ne (len .Values.tolerations) 0 }}
      tolerations:
      {{- range $tolerationKey := .Values.tolerations }}
        {{- if eq $tolerationKey "all" }}
        - operator: "Exists"
        {{- else }}
        - key: "{{ $tolerationKey }}"
          operator: "Exists"
        {{- end }}
      {{- end }}
      {{- end }}
      initContainers:

      containers:
        - name: serving
          {{- if .Values.image }}
          image: "{{ .Values.image }}"
          {{- end }}
          {{- if .Values.imagePullPolicy }}
          imagePullPolicy: "{{ .Values.imagePullPolicy }}"
          {{- end }}
          env:
          {{- if .Values.envs }}
          {{- range $key, $value := .Values.envs }}
            - name: "{{ $key }}"
              value: "{{ $value }}"
          {{- end }}
          {{- end }}
          {{- if ne .Values.command "" }}
          command:
          - "sh"
          - "-c"
          - "{{ .Values.command }}"
          {{- else }}
          command:
          - "sh"
          - "-c"
          args:
            - |
              /usr/bin/tensorflow_model_server --port={{ .Values.port }}{{- if .Values.restApiPort }} --rest_api_port={{ .Values.restApiPort }}
            {{- end }}{{- if ne .Values.modelConfigFileContent "" }} --model_config_file=/tmp/config{{- end }}{{- if gt (int $gpuMemory) 0 }} --per_process_gpu_memory_fraction=$(awk 'BEGIN{printf "%.2f",'$ALIYUN_COM_GPU_MEM_CONTAINER'/'$ALIYUN_COM_GPU_MEM_DEV'}')
            {{- end }}
          {{- end }}
          ports:
            - containerPort: {{ .Values.port }}
              name: serving
              protocol: TCP
            - containerPort: {{ .Values.restApiPort }}
              name: http-serving
          resources:
            limits:
              {{- if .Values.cpu }}
              cpu: {{ .Values.cpu }}
              {{- end }}
              {{- if .Values.memory }}
              memory: {{ .Values.memory }}
              {{- end }}
              {{- if gt (int $gpuCount) 0}}
              nvidia.com/gpu: {{ .Values.gpuCount }}
              {{- end }}
              {{- if gt (int $gpuMemory) 0}}
              aliyun.com/gpu-mem: {{ .Values.gpuMemory }}
              {{- end }}
          volumeMounts:
            {{- if .Values.modelDirs }}
            {{- range $pvcName, $destPath := .Values.modelDirs}}
            - name: "{{ $pvcName }}"
              mountPath: "{{ $destPath }}"
            {{- end }}
            {{- end }}
            {{- if ne .Values.modelConfigFileContent "" }}
            - name: config
              mountPath: /tmp
            {{- end }}
      volumes:
        {{- if .Values.modelDirs }}
        {{- range $pvcName, $destPath := .Values.modelDirs}}
        - name: "{{ $pvcName }}"
          persistentVolumeClaim:
            claimName: "{{ $pvcName }}"
        {{- end }}
        {{- end }}
        - name: config
          configMap:
            name: {{ template "tensorflow-serving.fullname" . }}-cm
            items:
            - key: modelConfigFileContent
              path: config
