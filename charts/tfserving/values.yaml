# Default values for tensorflow-serving.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

## Kubernetes configuration
## support NodePort, LoadBalancer
##
serviceType: ClusterIP

## serving name and version
serviceName:
serviceVersion:

## expose the service to the grpc client
port: 8500
rest_api_port: 8501
replicas: 1

# repository: "cheyang/tf-model-server-gpu"
image: "tensorflow/serving:latest"

imagePullPolicy: "IfNotPresent"

resources: {}
  #  limits:
  #    cpu: 1.0
  #    memory: 512Mi
  #    nvidia.com/gpu: 1
  #  requests:
  #    cpu: 1.0
  #    memory: 512Mi
  #    nvidia.com/gpu: 1


## The command and args to run the pod
#modelName: "inception"
#modelPath: "/serving/inception-export"

## the mount path inside the container
# mountPath: /serving/inception-export

persistence:
  enabled: true
  storageClass: ""
  size: 10Gi
  accessMode: ReadWriteOnce
  existingClaim: tf-serving-pvc
 # matchLabels: {}



