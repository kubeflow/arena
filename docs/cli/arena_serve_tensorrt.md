## arena serve tensorrt

Submit tensorRT inference serving job to deploy and serve machine learning models.

### Synopsis

Submit tensorRT inference serving job to deploy and serve machine learning models.

```
arena serve tensorrt [flags]
```

### Options

```
      --allow-metrics              Open Metric
  -a, --annotation stringArray     the annotations
      --command string             the command will inject to container's command.
      --cpu string                 the request cpu of each replica to run the serve.
  -d, --data stringArray           specify the trained models datasource to mount for serving, like <name_of_datasource>:<mount_point_on_job>
      --data-dir stringArray       specify the trained models datasource on host to mount for serving, like <host_path>:<mount_point_on_job>
      --enable-istio               enable Istio for serving or not (disable Istio by default)
  -e, --env stringArray            the environment variables
      --expose-service             expose service using Istio gateway for external access or not (not expose by default)
      --gpumemory int              the limit GPU memory of each replica to run the serve.
      --gpus int                   the limit GPU count of each replica to run the serve.
      --grpc-port int              the port of grpc serving server (default 8001)
  -h, --help                       help for tensorrt
      --http-port int              the port of http serving server (default 8000)
      --image string               the docker image name of serving job (default "registry.cn-beijing.aliyuncs.com/kube-ai/tensorrt-serving:18.12-py3")
      --image-pull-policy string   the policy to pull the image, and the default policy is IfNotPresent (default "IfNotPresent")
      --memory string              the request memory of each replica to run the serve.
      --metric-port int            the port of metrics server (default 8002)
      --model-store string         the path of tensorRT model path
      --name string                the serving name
      --replicas int               the replicas number of the serve job. (default 1)
      --selector stringArray       assigning jobs to some k8s particular nodes, usage: "--selector=key=value" or "--selector key=value" 
      --toleration stringArray     tolerate some k8s nodes with taints,usage: "--toleration taint-key" or "--toleration all" 
      --version string             the serving version
```

### Options inherited from parent commands

```
      --arena-namespace string   The namespace of arena system service, like tf-operator (default "arena-system")
      --config string            Path to a kube config. Only required if out-of-cluster
      --loglevel string          Set the logging level. One of: debug|info|warn|error (default "info")
  -n, --namespace string         the namespace of the job
      --pprof                    enable cpu profile
      --trace                    enable trace
```

### SEE ALSO

* [arena serve](arena_serve.md)	 - Serve a job.

###### Auto generated by spf13/cobra on 5-Mar-2021
