## arena serve custom

Submit custom serving to deploy and serve machine learning models.

### Synopsis

Submit custom serving to deploy and serve machine learning models.

```
arena serve custom [flags]
```

### Options

```
  -a, --annotation stringArray     the annotations, usage: "--annotation=key=value" or "--annotation key=value"
      --cpu string                 the request cpu of each replica to run the serve.
  -d, --data stringArray           specify the trained models datasource to mount for serving, like <name_of_datasource>:<mount_point_on_job>
      --data-subpath-expr stringArray  specify the datasource subpath to mount to the job by expression, like <name_of_datasource>:<mount_subpath_expr>
      --data-dir stringArray       specify the trained models datasource on host to mount for serving, like <host_path>:<mount_point_on_job>
      --device stringArray         specify the chip vendors and count that used for resources, such as amd.com/gpu=1 gpu.intel.com/i915=1.
      --enable-istio               enable Istio for serving or not (disable Istio by default)
  -e, --env stringArray            the environment variables
      --expose-service             expose service using Istio gateway for external access or not (not expose by default)
      --gpumemory int              the limit GPU memory of each replica to run the serve.
      --gpus int                   the limit GPU count of each replica to run the serve.
  -h, --help                       help for custom
      --image string               the docker image name of serving job
      --image-pull-policy string   the policy to pull the image, and the default policy is IfNotPresent (default "IfNotPresent")
      --memory string              the request memory of each replica to run the serve.
      --name string                the serving name
      --port int                   the port of gRPC listening port,default is 0 represents that don't create service listening on this port
      --replicas int               the replicas number of the serve job. (default 1)
      --restful-port int           the port of RESTful listening port,default is 0 represents that don't create service listening on this port
      --selector stringArray       assigning jobs to some k8s particular nodes, usage: "--selector=key=value" or "--selector key=value"
      --toleration stringArray     tolerate some k8s nodes with taints,usage: "--toleration taint-key" or "--toleration all"
      --version string             the serving version
```

### Options inherited from parent commands

```
      --arena-namespace string   The namespace of arena system service, like tf-operator (default "arena-system")
      --config string            Path to a kube config. Only required if out-of-cluster
      --loglevel string          Set the logging level. One of: debug|info|warn|error (default "info")
  -n, --namespace string         the namespace of the job
      --pprof                    enable cpu profile
      --trace                    enable trace
```

### SEE ALSO

* [arena serve](arena_serve.md)	 - Serve a job.

###### Auto generated by spf13/cobra on 5-Mar-2021
